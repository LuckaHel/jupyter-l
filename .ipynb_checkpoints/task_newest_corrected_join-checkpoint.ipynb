{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118939be-42d4-4a27-b4df-758358c8e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DoubleType, TimestampType\n",
    "from pyspark.sql.functions import col, to_date, concat, lit\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/mate/.local/lib/python3.10/site-packages/pyspark/\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"notebook\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "628aa5bc-3116-432b-836b-b7180bf82f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 13:02:42 WARN Utils: Your hostname, ces-shrd-1 resolves to a loopback address: 127.0.1.1; using 192.168.1.25 instead (on interface wlp0s20f3)\n",
      "24/05/03 13:02:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/03 13:02:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"My Spark Application\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01556bb0-76d9-41a3-8586-e6275b034fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, dayofweek,to_date, month, count, avg\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number,   sum, when\n",
    "\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path_flightdelay = \"./full_data_flightdelay.csv\"  # Replace with the path to your CSV file\n",
    "\n",
    "\n",
    "df_flightdelay = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(csv_file_path_flightdelay)\n",
    "\n",
    "\n",
    "# Read the CSV file using the manually defined schema\n",
    "csv_file_path_weather = \"./airport_weather_2019.csv\"  # Replace with your file path\n",
    "df_weather = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(csv_file_path_weather)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab71331e-dd5a-4fe4-96d8-971c711c5836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.select('DATE').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c09dbf2-39ce-42c3-9e35-35ffc9c47fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 13:02:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------------+--------------------+-------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "|MONTH|                NAME|              AWND|                PRCP|               SNOW|               SNWD|              TAVG|              TMAX|              TMIN|              WDF2|\n",
      "+-----+--------------------+------------------+--------------------+-------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "|    1|ALBANY INTERNATIO...| 9.604516129032257| 0.13838709677419353| 0.6096774193548388| 2.5064516129032257|23.967741935483872| 31.93548387096774|14.709677419354838|231.29032258064515|\n",
      "|    2|ALBANY INTERNATIO...| 8.803214285714287| 0.09571428571428572| 0.5035714285714284|              2.525|27.857142857142858|35.392857142857146|             19.75|233.57142857142858|\n",
      "|    3|ALBANY INTERNATIO...| 9.698064516129032|0.045000000000000005|0.21290322580645163|  1.348387096774194|35.354838709677416| 44.58064516129032| 25.70967741935484|248.06451612903226|\n",
      "|    4|ALBANY INTERNATIO...| 9.573666666666668|               0.144|               0.07|               0.04|50.166666666666664| 59.93333333333333| 39.63333333333333|             234.0|\n",
      "|    5|ALBANY INTERNATIO...| 7.662903225806452|  0.0993548387096774|                0.0|                0.0|58.096774193548384| 67.93548387096774| 49.12903225806452|210.96774193548387|\n",
      "|    6|ALBANY INTERNATIO...| 6.658999999999998| 0.17166666666666666|                0.0|                0.0| 68.53333333333333| 78.93333333333334| 57.06666666666667|229.66666666666666|\n",
      "|    7|ALBANY INTERNATIO...|5.3835483870967735| 0.12870967741935482|                0.0|                0.0| 75.96774193548387|  86.6774193548387|  65.6774193548387|211.93548387096774|\n",
      "|    8|ALBANY INTERNATIO...| 5.613870967741936|  0.1329032258064516|                0.0|                0.0|  71.2258064516129|  82.2258064516129| 61.16129032258065| 216.1290322580645|\n",
      "|    9|ALBANY INTERNATIO...| 5.965333333333336| 0.07433333333333333|                0.0|                0.0| 64.06666666666666|              75.2|              52.4|197.66666666666666|\n",
      "|   10|ALBANY INTERNATIO...| 6.400967741935484| 0.24129032258064514|                0.0|                0.0|53.774193548387096| 62.74193548387097| 44.41935483870968|212.58064516129033|\n",
      "|   11|ALBANY INTERNATIO...| 8.060333333333332|               0.094|0.07666666666666667|               0.16| 37.13333333333333|44.733333333333334|              28.7|214.33333333333334|\n",
      "|   12|ALBANY INTERNATIO...| 7.137096774193547| 0.14645161290322578| 0.9000000000000001|  3.761290322580645|30.483870967741936|36.903225806451616|22.677419354838708|225.16129032258064|\n",
      "|    1|ALBUQUERQUE INTER...| 6.725161290322581|0.016774193548387096|0.06451612903225806|0.12903225806451613| 35.32258064516129| 46.03225806451613|25.806451612903224|  257.741935483871|\n",
      "|    2|ALBUQUERQUE INTER...| 9.251428571428573|0.017857142857142856|               0.15|0.11071428571428572|39.285714285714285|              51.5|28.321428571428573|239.64285714285714|\n",
      "|    3|ALBUQUERQUE INTER...| 10.17451612903226|0.023548387096774197|                0.0|                0.0| 50.29032258064516| 62.16129032258065|38.225806451612904|217.09677419354838|\n",
      "|    4|ALBUQUERQUE INTER...| 8.835666666666665|0.033666666666666664|                0.0|                0.0|              57.6| 70.26666666666667| 44.43333333333333|             215.0|\n",
      "|    5|ALBUQUERQUE INTER...|  9.77741935483871|0.007741935483870969|                0.0|                0.0| 61.70967741935484|              75.0|48.193548387096776|217.74193548387098|\n",
      "|    6|ALBUQUERQUE INTER...| 9.857333333333333|0.002333333333333...|                0.0|                0.0|              74.4|              87.9|              59.7|205.66666666666666|\n",
      "|    7|ALBUQUERQUE INTER...|  8.42032258064516| 0.06290322580645161|                0.0|                0.0| 80.03225806451613| 93.48387096774194| 67.90322580645162| 163.2258064516129|\n",
      "|    8|ALBUQUERQUE INTER...|7.2377419354838715|0.013870967741935483|                0.0|                0.0| 78.96774193548387|  93.2258064516129| 66.03225806451613|192.25806451612902|\n",
      "+-----+--------------------+------------------+--------------------+-------------------+-------------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce\n",
    "\n",
    "# create new column for month and day_of_week values derived from date\n",
    "df_day_column = df_weather.withColumn(\"DATE_NEW\", to_date(col(\"DATE\"), \"M/d/yyyy\"))\n",
    "df_day_column = df_day_column.withColumn(\"DATE_NEW\", coalesce(df_day_column[\"DATE_NEW\"], to_date(df_day_column[\"DATE\"], 'yyyy-MM-dd')))\n",
    "\n",
    "df_day_column = df_day_column.withColumn(\"DAY_OF_WEEK\", dayofweek(col(\"DATE_NEW\").alias(\"DAY_OF_WEEK\")))\n",
    "df_day_column = df_day_column.withColumn(\"MONTH\", month(col(\"DATE_NEW\").alias(\"MONTH\")))\n",
    "#df_day_column = df_weather.withColumn(\"DAY_OF_WEEK\", dayofweek(col(\"DATE\").alias(\"DAY_OF_WEEK\"))) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df_day_column.show(n=2)\n",
    "df_day_column.createOrReplaceTempView(\"table1\")\n",
    "df_select = spark.sql(\"SELECT STATION, NAME,DAY_OF_WEEK,DATE, MONTH, AWND, PRCP, SNOW, SNWD, TAVG, TMAX, TMIN, WDF2 from table1\")\n",
    "#df_select.show(n=5)\n",
    "\n",
    "grouped_df = df_select.groupBy(\"MONTH\", \"NAME\").agg(\n",
    "    avg(\"AWND\").alias(\"AWND\"),\n",
    "    avg(\"PRCP\").alias(\"PRCP\"),\n",
    "    avg(\"SNOW\").alias(\"SNOW\"),\n",
    "    avg(\"SNWD\").alias(\"SNWD\"),\n",
    "    avg(\"TAVG\").alias(\"TAVG\"),\n",
    "    avg(\"TMAX\").alias(\"TMAX\"),\n",
    "    avg(\"TMIN\").alias(\"TMIN\"),\n",
    "    avg(\"WDF2\").alias(\"WDF2\")\n",
    ").orderBy(\"NAME\",\"MONTH\")\n",
    "\n",
    "\n",
    "grouped_df.show(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "426ff018-c155-4794-b558-80e9545644ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day_column.select('DATE_NEW').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "983d5e23-d23d-49cc-b55b-1427c1e118ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, split, col, lit, monotonically_increasing_id\n",
    "\n",
    "\n",
    "# Normalize joining columns\n",
    "grouped_df = grouped_df.withColumn(\"normalized_name\", lower(col(\"name\")))\n",
    "df_flightdelay = df_flightdelay.withColumn(\"normalized_name\", lower(split(col(\"departing_airport\"), \" \").getItem(0)))\n",
    "\n",
    "# Group by to investigate\n",
    "grouped_df_nn = grouped_df.groupBy(\"normalized_name\").agg(\n",
    "    count('*').alias('count')\n",
    ")\n",
    "\n",
    "grouped_df_name = grouped_df.groupBy(\"NAME\").agg(\n",
    "    count('*').alias('count')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66837d93-05eb-4042-bf6b-1159fcb003df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|   departing_airport|                name|\n",
      "+--------------------+--------------------+\n",
      "|memphis internati...|memphis internati...|\n",
      "|portland internat...|portland internat...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For 'grouped_df', transforming 'NAME' to lowercase and dropping duplicates based on the 'name' column\n",
    "grouped_df_lower = grouped_df.select(lower(col(\"NAME\")).alias(\"name\")).dropDuplicates(['name'])\n",
    "\n",
    "# For 'df_flightdelay', transforming 'DEPARTING_AIRPORT' to lowercase, casting it to string, and dropping duplicates based on the 'departing_airport' column\n",
    "df_flightdelay_lower = df_flightdelay.select(lower(col(\"DEPARTING_AIRPORT\")).alias(\"departing_airport\")).dropDuplicates(['departing_airport'])\n",
    "\n",
    "\n",
    "\n",
    "#join providing table that contain in the name column all distinct airports \n",
    "#from weather dataset and under departing_flight all distinc airports from delay dataset\n",
    "print(grouped_df_lower.count())\n",
    "print(df_flightdelay_lower.count())\n",
    "result_df = df_flightdelay_lower.alias(\"flight\").join(\n",
    "    grouped_df_lower.alias(\"grouped\"),\n",
    "    (col(\"grouped.name\").contains(col(\"flight.departing_airport\"))),\n",
    "    \"inner\"\n",
    ").select(\n",
    "    col(\"flight.departing_airport\").alias(\"departing_airport\"),\n",
    "    col(\"grouped.name\").alias(\"name\")\n",
    ")\n",
    "\n",
    "result_df.show(n=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad8c016-135e-4c98-83d9-f36c28a72c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- departing_airport: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- departing_airport: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name|   departing_airport|\n",
      "+--------------------+--------------------+\n",
      "|albuquerque inter...|tucson international|\n",
      "|anchorage ted ste...|charleston intern...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#modify dataframe such that df_result will contain the airports matched on join \n",
    "#and enhanced results will contain the df of unmatched airports for each dataset\n",
    "\n",
    "# Identifying non-matched entries\n",
    "non_matched_flight = df_flightdelay_lower.alias(\"flight\").join(\n",
    "    result_df.alias(\"result\"),\n",
    "    result_df.departing_airport == df_flightdelay_lower.departing_airport,\n",
    "    \"left_anti\"\n",
    ")\n",
    "\n",
    "non_matched_grouped = grouped_df_lower.alias(\"grouped\").join(\n",
    "    result_df.alias(\"result\"),\n",
    "    result_df.name == grouped_df_lower.name,\n",
    "    \"left_anti\"\n",
    ")\n",
    "\n",
    "\n",
    "# Add a unique ID to each DataFrame to facilitate the outer join\n",
    "result_df = result_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "non_matched_flight = non_matched_flight.withColumn(\"id\", monotonically_increasing_id())\n",
    "non_matched_grouped = non_matched_grouped.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "\n",
    "# Perform the outer joins using the unique IDs, result_df is now composed of matched airports\n",
    "enhanced_result_df = result_df.join(non_matched_flight, \"id\", \"outer\" ).join(non_matched_grouped, \"id\", \"outer\" )\n",
    "enhanced_result_df = enhanced_result_df.drop(\"id\")\n",
    "\n",
    "# Show the enhanced DataFrame with additional columns\n",
    "enhanced_result_df.printSchema()\n",
    "\n",
    "# Select columns, get rid of duplicates\n",
    "selected_columns = [col for col in enhanced_result_df.columns if col != 'name' and col != 'departing_airport'] + ['grouped.name'] + ['flight.departing_airport']\n",
    "\n",
    "#will contain unmatched airports for each dataset\n",
    "enhanced_result_df = enhanced_result_df.select(selected_columns)\n",
    "enhanced_result_df.drop('name','departing_airport')\n",
    "enhanced_result_df.show(n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a4742-f8c8-4707-97fe-808408ed0b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7419b18-8499-4eb5-b65b-3b70dda46365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----+--------------------+--------------------+\n",
      "|       delay_matched|     weather_matched|  id|   weather_unmatched|     delay_unmatched|\n",
      "+--------------------+--------------------+----+--------------------+--------------------+\n",
      "|memphis internati...|memphis internati...|   0|albuquerque inter...|tucson international|\n",
      "|portland internat...|portland internat...|   1|anchorage ted ste...|charleston intern...|\n",
      "|richmond internat...|richmond internat...|   2|asheville airport...|         kent county|\n",
      "|washington dulles...|washington dulles...|   3|aspen pitkin co a...|     eppley airfield|\n",
      "|mccarran internat...|mccarran internat...|   4|atlanta hartsfiel...|phoenix sky harbo...|\n",
      "|  birmingham airport|birmingham airpor...|   5|austin bergstrom ...|palm springs inte...|\n",
      "|kansas city inter...|kansas city inter...|   6|baltimore washing...|pittsburgh intern...|\n",
      "|orlando internati...|orlando internati...|   7|baton rouge metro...|       lihue airport|\n",
      "|   will rogers world|oklahoma city wil...|   8|       boston, ma us|       orange county|\n",
      "|syracuse hancock ...|syracuse hancock ...|   9|bozeman gallatin ...|port columbus int...|\n",
      "|philadelphia inte...|philadelphia inte...|  10|buffalo johnson c...|greenville-sparta...|\n",
      "|palm beach intern...|west palm beach i...|  11|buffalo niagara i...|     kahului airport|\n",
      "|  boise air terminal|boise air termina...|  12|burlington intern...|minneapolis-st pa...|\n",
      "|san francisco int...|san francisco int...|  13|cedar rapids muni...|raleigh-durham in...|\n",
      "|nashville interna...|nashville interna...|  14|charleston intl. ...|long beach daughe...|\n",
      "|san antonio inter...|san antonio inter...|  15|charlotte douglas...|seattle internati...|\n",
      "|newark liberty in...|newark liberty in...|  16|chattanooga airpo...|             keahole|\n",
      "|bradley internati...|hartford bradley ...|  17|chicago ohare int...|theodore francis ...|\n",
      "|salt lake city in...|salt lake city in...|  18|cincinnati munici...|   douglas municipal|\n",
      "|jacksonville inte...|jacksonville inte...|  19|cleveland hopkins...|friendship intern...|\n",
      "| miami international|miami internation...|  20|colorado springs ...|   dallas love field|\n",
      "|honolulu internat...|honolulu internat...|  21|columbus ohio sta...|ontario internati...|\n",
      "|           laguardia|laguardia airport...|  22|dallas faa airpor...|sacramento intern...|\n",
      "|spokane internati...|spokane internati...|  23|dayton wright bro...|greater buffalo i...|\n",
      "|el paso internati...|el paso internati...|  24|denver internatio...|cleveland-hopkins...|\n",
      "|san jose internat...|san jose internat...|  25|des moines intern...|detroit metro way...|\n",
      "|albany international|albany internatio...|  26|desert resorts re...|stapleton interna...|\n",
      "|norfolk internati...|norfolk internati...|  27|detroit metro air...|ronald reagan was...|\n",
      "|los angeles inter...|los angeles inter...|  28|fayetteville spri...| logan international|\n",
      "|     william p hobby|houston william p...|  29|fort lauderdale i...|indianapolis muni...|\n",
      "| tampa international|tampa internation...|  30|fort myers sw flo...| tulsa international|\n",
      "|houston intercont...|houston intercont...|  31|fort worth meacha...|   atlanta municipal|\n",
      "|                NULL|                NULL|NULL|fresno yosemite i...|metropolitan oakl...|\n",
      "|                NULL|                NULL|NULL|grand island cent...|des moines municipal|\n",
      "|                NULL|                NULL|NULL|grand rapids gera...|    standiford field|\n",
      "|                NULL|                NULL|NULL|greensboro airpor...|john f. kennedy i...|\n",
      "|                NULL|                NULL|NULL|greenville downto...|cincinnati/northe...|\n",
      "|                NULL|                NULL|NULL|huntsville intnl ...|dallas fort worth...|\n",
      "|                NULL|                NULL|NULL|indianapolis inte...|fort lauderdale-h...|\n",
      "|                NULL|                NULL|NULL|jackson internati...|puerto rico inter...|\n",
      "|                NULL|                NULL|NULL|kailua kona ke ah...|hollywood-burbank...|\n",
      "|                NULL|                NULL|NULL|knoxville airport...|chicago o'hare in...|\n",
      "|                NULL|                NULL|NULL|lexington bluegra...|piedmont triad in...|\n",
      "|                NULL|                NULL|NULL|lihue weather ser...|san diego interna...|\n",
      "|                NULL|                NULL|NULL|louisville intern...|reno/tahoe intern...|\n",
      "|                NULL|                NULL|NULL|madison dane co r...|anchorage interna...|\n",
      "|                NULL|                NULL|NULL|manchester airpor...|savannah/hilton h...|\n",
      "|                NULL|                NULL|NULL|milwaukee mitchel...|southwest florida...|\n",
      "|                NULL|                NULL|NULL|minneapolis st. p...|louis armstrong n...|\n",
      "|                NULL|                NULL|NULL|new orleans airpo...|        mcghee tyson|\n",
      "|                NULL|                NULL|NULL|newport state air...|lambert-st. louis...|\n",
      "|                NULL|                NULL|NULL|north little rock...|general mitchell ...|\n",
      "|                NULL|                NULL|NULL|north myrtle beac...|austin - bergstro...|\n",
      "|                NULL|                NULL|NULL|phoenix airport, ...|chicago midway in...|\n",
      "|                NULL|                NULL|NULL|pittsburgh allegh...|albuquerque inter...|\n",
      "|                NULL|                NULL|NULL|port arthur se tx...|         sanford nas|\n",
      "|                NULL|                NULL|NULL|portland jetport,...|         truax field|\n",
      "|                NULL|                NULL|NULL|raleigh airport, ...|         adams field|\n",
      "|                NULL|                NULL|NULL|rapid city region...|northwest arkansa...|\n",
      "|                NULL|                NULL|NULL| reno airport, nv us|rochester monroe ...|\n",
      "|                NULL|                NULL|NULL|rochester greater...|james m cox/dayto...|\n",
      "|                NULL|                NULL|NULL|sacramento metrop...|  pensacola regional|\n",
      "|                NULL|                NULL|NULL|san diego interna...|myrtle beach inte...|\n",
      "|                NULL|                NULL|NULL|san juan l m mari...|portland internat...|\n",
      "|                NULL|                NULL|NULL|santa ana john wa...|                NULL|\n",
      "|                NULL|                NULL|NULL|savannah internat...|                NULL|\n",
      "|                NULL|                NULL|NULL|seattle tacoma ai...|                NULL|\n",
      "|                NULL|                NULL|NULL|springfield weath...|                NULL|\n",
      "|                NULL|                NULL|NULL|st louis lambert ...|                NULL|\n",
      "|                NULL|                NULL|NULL|tallahassee airpo...|                NULL|\n",
      "|                NULL|                NULL|NULL|tallahassee regio...|                NULL|\n",
      "|                NULL|                NULL|NULL|traverse city che...|                NULL|\n",
      "|                NULL|                NULL|NULL|wichita colonel j...|                NULL|\n",
      "|                NULL|                NULL|NULL|wilmington intern...|                NULL|\n",
      "+--------------------+--------------------+----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dataframe that contains airports matched and unmatched result from the join\n",
    "# Rename columns in result_df\n",
    "result_df = result_df.withColumnRenamed(\"name\", \"weather_matched\") \\\n",
    "                     .withColumnRenamed(\"departing_airport\", \"delay_matched\")\n",
    "\n",
    "# Rename columns in enhanced_result_df\n",
    "enhanced_result_df = enhanced_result_df.withColumnRenamed(\"name\", \"weather_unmatched\") \\\n",
    "                                       .withColumnRenamed(\"departing_airport\", \"delay_unmatched\")\n",
    "\n",
    "# Optional: If you need to ensure the rows are matched by order, add an index column to each DataFrame\n",
    "result_df = result_df.withColumn(\"index\", monotonically_increasing_id())\n",
    "enhanced_result_df = enhanced_result_df.withColumn(\"index\", monotonically_increasing_id())\n",
    "\n",
    "# Join DataFrames on the index column\n",
    "matched_and_unmatched_airports = result_df.join(\n",
    "    enhanced_result_df,\n",
    "    on=\"index\",\n",
    "    how=\"outer\"  # Use \"outer\" to include all rows from both DataFrames\n",
    ")\n",
    "\n",
    "# Drop the index column as it's no longer needed after joining\n",
    "matched_and_unmatched_airports = matched_and_unmatched_airports.drop(\"index\", 'name', 'departing_airport')\n",
    "\n",
    "# Show the resulting DataFrame structure\n",
    "matched_and_unmatched_airports.show(n = 76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e793e46b-e808-4fea-ad76-6a90cef070c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-null strings in the 'name' column: 32 32 74 64\n"
     ]
    }
   ],
   "source": [
    "#count the amount of airports for each clumn in the enhanced dataset dataframe \n",
    "\n",
    "non_null_name_count = result_df.filter(col(\"name\").isNotNull()).count()\n",
    "non_null_name_count1 = result_df.filter(col(\"departing_airport\").isNotNull()).count()\n",
    "non_null_name_count2 = enhanced_result_df.filter(col(\"weather_unmatched\").isNotNull()).count()\n",
    "non_null_name_count3 = enhanced_result_df.filter(col(\"delay_unmatched\").isNotNull()).count()\n",
    "print(\"Number of non-null strings in the 'name' column:\", non_null_name_count, non_null_name_count1,non_null_name_count2, non_null_name_count3)\n",
    "\n",
    "# Display the filtered DataFrame and print the counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf47076e-52b6-4634-8e03-35ced09409df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store the parsed data\n",
    "data = []\n",
    "\n",
    "# Open the text file and parse it line by line\n",
    "with open('./airports.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line by comma to extract the needed parts\n",
    "        parts = line.split(',')\n",
    "        \n",
    "        # Check if the line has enough parts to avoid index errors\n",
    "        if len(parts) >= 4:\n",
    "            # Extract and clean the desired parts\n",
    "            # Remove quotation marks and extra spaces if present\n",
    "            name = parts[1].strip('\"').strip()\n",
    "            city = parts[2].strip('\"').strip()\n",
    "            country = parts[3].strip('\"').strip()\n",
    "            \n",
    "            # Combine the first two parts into one column, and keep the country as the second column\n",
    "            combined = f\"{name}, {city}, {country}\"\n",
    "            data.append(combined)\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df_airports = pd.DataFrame(data, columns=['Airport and City'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a73d9-8f5b-4070-9e51-0d8af85f4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c3c61f3-a54e-4edc-9d65-d4d2e84bf106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 645:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|         airport|\n",
      "+----------------+\n",
      "| eppley airfield|\n",
      "|        kahului |\n",
      "|greater buffalo |\n",
      "|     sacramento |\n",
      "| chicago o'hare |\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Get all airport names into one table\n",
    "df_delay_unique_airport = df_flightdelay.select('DEPARTING_AIRPORT').distinct().withColumnRenamed(\"DEPARTING_AIRPORT\", \"airport\")\n",
    "df_weather_unique_airport = df_weather.select('NAME').distinct().withColumnRenamed(\"NAME\", \"airport\")\n",
    "\n",
    "df_union = df_delay_unique_airport.union(df_weather_unique_airport)\n",
    "\n",
    "def filter_out_useless_parts_of_string(airport_name):\n",
    "    useless_words = [\"international\", \"airport\", \"regional\"]\n",
    "\n",
    "    modified = airport_name.lower()\n",
    "    for word in useless_words:\n",
    "        modified = modified.replace(word,\"\")\n",
    "        \n",
    "    return modified\n",
    "    \n",
    "filter_string_udf = udf(filter_out_useless_parts_of_string, StringType())\n",
    "\n",
    "df_union = df_union.select(filter_string_udf(col('airport'))).withColumnRenamed(\"filter_out_useless_parts_of_string(airport)\", \"airport\")\n",
    "df_union.show(n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8392322f-bd5d-47ea-ad10-763847e59700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+-----+\n",
      "|   weather_unmatched|Airport and City_match|Score|\n",
      "+--------------------+----------------------+-----+\n",
      "|albuquerque inter...|  Malta Internation...|   88|\n",
      "|anchorage ted ste...|  Ted Stevens Ancho...|   93|\n",
      "|asheville airport...|  Asheville Regiona...|   85|\n",
      "+--------------------+----------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+----------------------+\n",
      "|     weather_matched|Airport and City_match|\n",
      "+--------------------+----------------------+\n",
      "|memphis internati...|  Memphis Internati...|\n",
      "|portland internat...|  Portland Internat...|\n",
      "|richmond internat...|  Richmond Internat...|\n",
      "+--------------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "def get_matches(df1, col1, df2, col2, threshold=40):\n",
    "    # Convert each column to a list for processing, ensuring to drop NA values\n",
    "    list1 = df1[col1].dropna().tolist()\n",
    "    list2 = df2[col2].dropna().tolist()\n",
    "\n",
    "    # Find best matches with a score above the threshold\n",
    "    matches = []\n",
    "    for item in list1:\n",
    "        # Use process.extractOne to find the best match for each item from list1 in list2\n",
    "        best_match = process.extractOne(item, list2, scorer=fuzz.token_set_ratio)\n",
    "        if best_match and best_match[1] >= threshold:\n",
    "            matches.append((item, best_match[0], best_match[1]))\n",
    "\n",
    "    # Return matches as a DataFrame for better visualization\n",
    "    return pd.DataFrame(matches, columns=[col1, col2 + '_match', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "935bd86e-6047-4e87-8d53-330b4cbd3419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add official airports using fuzzywuzzy\n",
    "# Assuming 'matched_and_unmatched_airports' is your PySpark DataFrame\n",
    "pandas_df = df_union.toPandas()  # Convert to Pandas DataFrame\n",
    "\n",
    "# Example usage (ensure df1 and df2 are already defined and loaded with your data)\n",
    "df_matches_airports = get_matches(pandas_df, 'airport', df_airports, 'Airport and City')\n",
    "\n",
    "spark_df_airports = spark.createDataFrame(df_matches_airports)\n",
    "# Show the DataFrame to verify conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5415602-ebd2-4bdd-a27b-13ec68b697a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joining_table = spark_df_airports.select(\"airport\", \"Airport and City_match\")\n",
    "delay_table = df_flightdelay.withColumn(\"DEPARTING_AIRPORT\", filter_string_udf('DEPARTING_AIRPORT'))\n",
    "weather_table = df_day_column.withColumn(\"NAME\", filter_string_udf('NAME'))\n",
    "\n",
    "delay_joined = delay_table.join(joining_table, joining_table.airport == delay_table.DEPARTING_AIRPORT, 'inner')\n",
    "weather_joined = weather_table.join(joining_table, joining_table.airport == weather_table.NAME, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f51744-7a82-4551-aeb6-e5be6440d152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fe908b1-39e2-44d4-8c86-5408294eb5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 19:32:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , MONTH, DAY_OF_WEEK, DEP_DEL15, DEP_TIME_BLK, DISTANCE_GROUP, SEGMENT_NUMBER, CONCURRENT_FLIGHTS, NUMBER_OF_SEATS, CARRIER_NAME, AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH, AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE, FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS, PLANE_AGE, DEPARTING_AIRPORT, LATITUDE, LONGITUDE, PREVIOUS_AIRPORT\n",
      " Schema: _c0, MONTH, DAY_OF_WEEK, DEP_DEL15, DEP_TIME_BLK, DISTANCE_GROUP, SEGMENT_NUMBER, CONCURRENT_FLIGHTS, NUMBER_OF_SEATS, CARRIER_NAME, AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH, AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE, FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS, PLANE_AGE, DEPARTING_AIRPORT, LATITUDE, LONGITUDE, PREVIOUS_AIRPORT\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/mate/repos/LuckaEvolucne/full_data_flightdelay.csv\n",
      "[Stage 820:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+----------------------+------+---------+------------+--------------+--------------+------------------+---------------+--------------------+---------------------+---------------------+-----------------------------+------------------------+------------------------+-----------------------+--------------------+---------+-----------------+--------+---------+----------------+---------------+-----------+-----------+--------------------+----------+-----+----+----+----+----+----+----+----+-----+-----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----------+--------------------+\n",
      "|MONTH|DAY_OF_WEEK|Airport and City_match|   _c0|DEP_DEL15|DEP_TIME_BLK|DISTANCE_GROUP|SEGMENT_NUMBER|CONCURRENT_FLIGHTS|NUMBER_OF_SEATS|        CARRIER_NAME|AIRPORT_FLIGHTS_MONTH|AIRLINE_FLIGHTS_MONTH|AIRLINE_AIRPORT_FLIGHTS_MONTH|AVG_MONTHLY_PASS_AIRPORT|AVG_MONTHLY_PASS_AIRLINE|FLT_ATTENDANTS_PER_PASS|GROUND_SERV_PER_PASS|PLANE_AGE|DEPARTING_AIRPORT|LATITUDE|LONGITUDE|PREVIOUS_AIRPORT|normalized_name|    airport|    STATION|                NAME|      DATE| AWND|PGTM|PRCP|SNOW|SNWD|TAVG|TMAX|TMIN| WDF2| WDF5|WSF2|WSF5|WT01|WT02|WT03|WT04|WT05|WT06|WT07|WT08|WT09|WESD|WT10|PSUN|TSUN|SN32|SX32|TOBS|WT11|  DATE_NEW|             airport|\n",
      "+-----+-----------+----------------------+------+---------+------------+--------------+--------------+------------------+---------------+--------------------+---------------------+---------------------+-----------------------------+------------------------+------------------------+-----------------------+--------------------+---------+-----------------+--------+---------+----------------+---------------+-----------+-----------+--------------------+----------+-----+----+----+----+----+----+----+----+-----+-----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----------+--------------------+\n",
      "|    1|          1|  Charleston Air Fo...|223396|        0|   0800-0859|           2.0|             1|                 2|            129|Delta Air Lines Inc.|                 1665|                73508|                        326.0|                  197188|                12460183|     0.0001441658849878|  0.0001486602009422|       11|      charleston |  32.899|  -80.039|            NONE|     charleston|charleston |USW00013880|charleston intl. ...|2019-01-27| 2.46|NULL| 0.0| 0.0| 0.0|NULL|52.0|32.0|350.0| 60.0| 8.1|11.0|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|47.0|54.0|NULL|NULL|2019-01-27|charleston intl. ...|\n",
      "|    1|          1|  Charleston Air Fo...|223396|        0|   0800-0859|           2.0|             1|                 2|            129|Delta Air Lines Inc.|                 1665|                73508|                        326.0|                  197188|                12460183|     0.0001441658849878|  0.0001486602009422|       11|      charleston |  32.899|  -80.039|            NONE|     charleston|charleston |USW00013880|charleston intl. ...|2019-01-20|15.43|NULL|0.65| 0.0| 0.0|NULL|69.0|40.0|200.0|210.0|35.1|47.0| 1.0|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|NULL|55.0|60.0|NULL|NULL|2019-01-20|charleston intl. ...|\n",
      "+-----+-----------+----------------------+------+---------+------------+--------------+--------------+------------------+---------------+--------------------+---------------------+---------------------+-----------------------------+------------------------+------------------------+-----------------------+--------------------+---------+-----------------+--------+---------+----------------+---------------+-----------+-----------+--------------------+----------+-----+----+----+----+----+----+----+----+-----+-----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#delay_joined.show(n=3)\n",
    "#weather_joined.show(n=3)\n",
    "\n",
    "# Convert integer columns in df1 to strings\n",
    "weather_joined = weather_joined.withColumn(\"MONTH\", col(\"MONTH\").cast(\"string\")) \\\n",
    "         .withColumn(\"DAY_OF_WEEK\", col(\"DAY_OF_WEEK\").cast(\"string\"))\n",
    "\n",
    "result_joined = delay_joined.join(weather_joined, [\"MONTH\",\"DAY_OF_WEEK\",\"Airport and City_match\"], 'inner')\n",
    "\n",
    "result_joined.show(n=2)\n",
    "\n",
    "#weather_join_delay = weather_joined.join(delay_joined, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "610613f2-db54-482d-9caf-58d73ddcfda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15051649"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e696e498-fb88-4ada-afbe-14974a82a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- Airport and City_match: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- DISTANCE_GROUP: string (nullable = true)\n",
      " |-- SEGMENT_NUMBER: string (nullable = true)\n",
      " |-- CONCURRENT_FLIGHTS: string (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: string (nullable = true)\n",
      " |-- CARRIER_NAME: string (nullable = true)\n",
      " |-- AIRPORT_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AIRLINE_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AIRLINE_AIRPORT_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AVG_MONTHLY_PASS_AIRPORT: string (nullable = true)\n",
      " |-- AVG_MONTHLY_PASS_AIRLINE: string (nullable = true)\n",
      " |-- FLT_ATTENDANTS_PER_PASS: string (nullable = true)\n",
      " |-- GROUND_SERV_PER_PASS: string (nullable = true)\n",
      " |-- PLANE_AGE: string (nullable = true)\n",
      " |-- DEPARTING_AIRPORT: string (nullable = true)\n",
      " |-- PREVIOUS_AIRPORT: string (nullable = true)\n",
      " |-- AWND: string (nullable = true)\n",
      " |-- PGTM: string (nullable = true)\n",
      " |-- PRCP: string (nullable = true)\n",
      " |-- SNOW: string (nullable = true)\n",
      " |-- SNWD: string (nullable = true)\n",
      " |-- TAVG: string (nullable = true)\n",
      " |-- TMAX: string (nullable = true)\n",
      " |-- TMIN: string (nullable = true)\n",
      " |-- WDF2: string (nullable = true)\n",
      " |-- WDF5: string (nullable = true)\n",
      " |-- WSF2: string (nullable = true)\n",
      " |-- WSF5: string (nullable = true)\n",
      " |-- WT01: string (nullable = true)\n",
      " |-- WT02: string (nullable = true)\n",
      " |-- WT03: string (nullable = true)\n",
      " |-- WT04: string (nullable = true)\n",
      " |-- WT05: string (nullable = true)\n",
      " |-- WT06: string (nullable = true)\n",
      " |-- WT07: string (nullable = true)\n",
      " |-- WT08: string (nullable = true)\n",
      " |-- WT09: string (nullable = true)\n",
      " |-- WESD: string (nullable = true)\n",
      " |-- WT10: string (nullable = true)\n",
      " |-- PSUN: string (nullable = true)\n",
      " |-- TSUN: string (nullable = true)\n",
      " |-- SN32: string (nullable = true)\n",
      " |-- SX32: string (nullable = true)\n",
      " |-- TOBS: string (nullable = true)\n",
      " |-- WT11: string (nullable = true)\n",
      " |-- DATE_NEW: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f2c69994-b87c-4754-9200-b20cbcb50dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "# LATITUDE, LONGITUDE, STATION, MONTH, airport, normalized_name, NAME, _c0\n",
    "result_joined = result_joined.drop(\"LATITUDE\", \"LONGITUDE\", \"STATION\", \"MONTH\", \\\n",
    "                                   \"airport\", \"normalized_name\", \"NAME\", \"_c0\", \\\n",
    "                                   \"DATE\", \"AIRLINE_FLIGHTS_MONTH\", \"AVG_MONTHLY_PASS_AIRLINE\" \\\n",
    "                                   \"DEPARTING_AIRPORT\", \"PGTM\", \"WDF5\", \"WDF2\", \"WSF2\", \"WSF5\", \\\n",
    "                                   \"SN32\", \"SX32\", \"TOBS\",\"WESD\", \"PSUN\",\"TSUN\")\n",
    "\n",
    "df = result_joined\n",
    "#result_joined.count()\n",
    "#result_joined.select(\"CONCURRENT_FLIGHTS\").filter(col(\"CONCURRENT_FLIGHTS\").isNotNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0bc58762-a744-44fe-9c6e-8272a8e5e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow is null:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow is not null:  15051649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1942:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole df:  15051649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"TMIN\", df[\"TMIN\"].cast(\"float\"))\n",
    "df = df.withColumn(\"PRCP\", df[\"PRCP\"].cast(\"float\"))\n",
    "\n",
    "\n",
    "#print(df.count())\n",
    "\n",
    "\n",
    "#count = df.filter(((col(\"PRCP\") > 0.0) & (col(\"TMIN\") < 3.0)) & (col(\"SNOW\").isNull() | (col(\"SNOW\") == ''))).count()\n",
    "\n",
    "df = df.withColumn(\"SNOW\", when(col(\"TMIN\") > 3, 0).otherwise(col(\"SNOW\")))\n",
    "df = df.withColumn(\"SNOW\", when( \\\n",
    "                    (col(\"SNOW\").isNull() | (col(\"SNOW\") == '')) & (col(\"PRCP\") > 0), col(\"PRCP\") \\\n",
    "                               ).otherwise(lit(0)))\n",
    "\n",
    "count = df.filter(col(\"SNOW\").isNull() | (col(\"SNOW\") == '')).count()\n",
    "print(\"Snow is null: \",count)\n",
    "count = df.filter(col(\"SNOW\").isNotNull()).count()\n",
    "print(\"Snow is not null: \",count)\n",
    "\n",
    "print(\"Whole df: \",df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0cfb6937-44ac-49c8-b956-12837d92fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify temperatures, create new flag column EXTREME_WEATHER based on TMIN and TMAX and drop all others\n",
    "\n",
    "\n",
    "# Since TMAX and TMIN are strings, you need to convert them to integers before comparison\n",
    "df = df.withColumn(\"TMAX\", df[\"TMAX\"].cast(\"integer\"))\n",
    "df = df.withColumn(\"TMIN\", df[\"TMIN\"].cast(\"integer\"))\n",
    "\n",
    "# Creating the EXTREME_WEATHER column based on the conditions provided\n",
    "df = df.withColumn(\"EXTREME_WEATHER\", \n",
    "                   when((col(\"TMAX\") > 40) | (col(\"TMIN\") < 0), 1)\n",
    "                   .otherwise(0))\n",
    "\n",
    "df = df.drop(\"TMIN\", \"TMAX\", \"TAVG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b2395a6b-e573-4f21-bcc3-61898a3f3300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT07', 'WT08', 'WT09', 'WT10', 'WT11']\n",
      "WT01+WT02+WT03+WT04+WT05+WT06+WT07+WT08+WT09+WT10+WT11\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# Replace all WT** with column which adds these extreme weather conditions into one value\n",
    "values_as_strings = [f\"WT{i:02}\" for i in range(1, 12)]\n",
    "print(values_as_strings)\n",
    "print(\"+\".join(values_as_strings))\n",
    "\n",
    "for column_name in values_as_strings:\n",
    "    df = df.withColumn(column_name, df[column_name].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4c36c5ab-63ce-4591-96e2-7780413559a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- Airport and City_match: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- DISTANCE_GROUP: string (nullable = true)\n",
      " |-- SEGMENT_NUMBER: string (nullable = true)\n",
      " |-- CONCURRENT_FLIGHTS: string (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: string (nullable = true)\n",
      " |-- CARRIER_NAME: string (nullable = true)\n",
      " |-- AIRPORT_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AIRLINE_AIRPORT_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AVG_MONTHLY_PASS_AIRPORT: string (nullable = true)\n",
      " |-- FLT_ATTENDANTS_PER_PASS: string (nullable = true)\n",
      " |-- GROUND_SERV_PER_PASS: string (nullable = true)\n",
      " |-- PLANE_AGE: string (nullable = true)\n",
      " |-- DEPARTING_AIRPORT: string (nullable = true)\n",
      " |-- PREVIOUS_AIRPORT: string (nullable = true)\n",
      " |-- AWND: string (nullable = true)\n",
      " |-- PRCP: string (nullable = true)\n",
      " |-- SNOW: string (nullable = true)\n",
      " |-- WT01: integer (nullable = true)\n",
      " |-- WT02: integer (nullable = true)\n",
      " |-- WT03: integer (nullable = true)\n",
      " |-- WT04: integer (nullable = true)\n",
      " |-- WT05: integer (nullable = true)\n",
      " |-- WT06: integer (nullable = true)\n",
      " |-- WT07: integer (nullable = true)\n",
      " |-- WT08: integer (nullable = true)\n",
      " |-- WT09: integer (nullable = true)\n",
      " |-- WT10: integer (nullable = true)\n",
      " |-- WT11: integer (nullable = true)\n",
      " |-- DATE_NEW: date (nullable = true)\n",
      " |-- EXTREME_WEATHER: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "02f966b1-c944-4e85-bdc6-cfda4eede96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "total_wt_column = reduce(lambda a, b: a + b, [coalesce(col(c), lit(0)) for c in wt_columns])\n",
    "\n",
    "df = df.withColumn('EXTREME_WEATHER_WT', total_wt_column)\n",
    "\n",
    "df = df.drop('WT01', 'WT02', 'WT03', 'WT04', 'WT05', 'WT06', 'WT07', 'WT08', 'WT09', 'WT10', 'WT11')\n",
    "\n",
    "#df.printSchema()\n",
    "\n",
    "#df.groupBy(\"EXTREME_WEATHER_WT\").count().orderBy(\"EXTREME_WEATHER_WT\").show()\n",
    "#df.select(\"EXTREME_WEATHER_WT\").show(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "16071707-3de0-41a5-80bb-f55cb3982655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DAY_OF_WEEK: string (nullable = true)\n",
      " |-- Airport and City_match: string (nullable = true)\n",
      " |-- DEP_DEL15: string (nullable = true)\n",
      " |-- DEP_TIME_BLK: string (nullable = true)\n",
      " |-- DISTANCE_GROUP: string (nullable = true)\n",
      " |-- SEGMENT_NUMBER: string (nullable = true)\n",
      " |-- CONCURRENT_FLIGHTS: string (nullable = true)\n",
      " |-- NUMBER_OF_SEATS: string (nullable = true)\n",
      " |-- CARRIER_NAME: string (nullable = true)\n",
      " |-- AIRPORT_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AIRLINE_AIRPORT_FLIGHTS_MONTH: string (nullable = true)\n",
      " |-- AVG_MONTHLY_PASS_AIRPORT: string (nullable = true)\n",
      " |-- FLT_ATTENDANTS_PER_PASS: string (nullable = true)\n",
      " |-- GROUND_SERV_PER_PASS: string (nullable = true)\n",
      " |-- PLANE_AGE: string (nullable = true)\n",
      " |-- DEPARTING_AIRPORT: string (nullable = true)\n",
      " |-- PREVIOUS_AIRPORT: string (nullable = true)\n",
      " |-- AWND: string (nullable = true)\n",
      " |-- PRCP: string (nullable = true)\n",
      " |-- SNOW: string (nullable = true)\n",
      " |-- DATE_NEW: date (nullable = true)\n",
      " |-- EXTREME_WEATHER: integer (nullable = false)\n",
      " |-- EXTREME_WEATHER_WT: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a7fdc75a-e3cc-481f-967d-469dff1dc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "# Define a function to count nulls and empty strings\n",
    "def count_nulls_and_empties(df):\n",
    "    # Use aggregation to sum up each condition of being null or empty across all columns\n",
    "    exprs = [count(when(col(c).isNull() | (col(c) == \"\"), c)).alias(c) for c in df.columns]\n",
    "    return df.agg(*exprs)\n",
    "\n",
    "# Apply the function to count nulls and empties\n",
    "nulls_and_empties_count = count_nulls_and_empties(df)\n",
    "\n",
    "# Show the result\n",
    "#nulls_and_empties_count.show()\n",
    "\n",
    "#df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1a1a8912-5e86-4fcc-8fda-2702c487b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2045:=================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------+---------+------------+--------------+------------------+---------------+------------+---------------------+-----------------------------+------------------------+--------------------+---------+-----------------+----------------+----+--------+---------------+------------------+----+----+--------------+-----------------------+\n",
      "|DAY_OF_WEEK|Airport and City_match|DEP_DEL15|DEP_TIME_BLK|SEGMENT_NUMBER|CONCURRENT_FLIGHTS|NUMBER_OF_SEATS|CARRIER_NAME|AIRPORT_FLIGHTS_MONTH|AIRLINE_AIRPORT_FLIGHTS_MONTH|AVG_MONTHLY_PASS_AIRPORT|GROUND_SERV_PER_PASS|PLANE_AGE|DEPARTING_AIRPORT|PREVIOUS_AIRPORT|SNOW|DATE_NEW|EXTREME_WEATHER|EXTREME_WEATHER_WT|AWND|PRCP|DISTANCE_GROUP|FLT_ATTENDANTS_PER_PASS|\n",
      "+-----------+----------------------+---------+------------+--------------+------------------+---------------+------------+---------------------+-----------------------------+------------------------+--------------------+---------+-----------------+----------------+----+--------+---------------+------------------+----+----+--------------+-----------------------+\n",
      "|          0|                     0|        0|           0|             0|                 0|              0|           0|                    0|                       225900|                       0|                   0|        0|                0|               0|   0|       0|              0|                 0|   0|   0|             0|                      0|\n",
      "+-----------+----------------------+---------+------------+--------------+------------------+---------------+------------+---------------------+-----------------------------+------------------------+--------------------+---------+-----------------+----------------+----+--------+---------------+------------------+----+----+--------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fill in missing values, for example AWND and PRCP\n",
    "\n",
    "from pyspark.sql.functions import avg, col, coalesce, month, median\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Define a window spec partitioned by month\n",
    "window_spec = Window.partitionBy(month(\"DATE_NEW\"))\n",
    "\n",
    "# Assuming 'column_name' is the column with null values you want to fill\n",
    "avg_column = avg(col(\"AWND\")).over(window_spec)\n",
    "avg_prcp = avg(col(\"PRCP\")).over(window_spec)\n",
    "med_column = median(col(\"FLT_ATTENDANTS_PER_PASS\")).over(window_spec)\n",
    "\n",
    "\n",
    "# Replace nulls with the average of that month\n",
    "df = df.withColumn(\"AWND_filled\", coalesce(col(\"AWND\"), avg_column))\n",
    "df = df.withColumn(\"PRCP_filled\", coalesce(col(\"PRCP\"), avg_prcp))\n",
    "df = df.withColumn(\"DISTANCE_GROUP_filled\", coalesce(col(\"DISTANCE_GROUP\"), lit(\"1\")))\n",
    "df = df.withColumn(\"FLT_ATTENDANTS_PER_PASS_filled\", coalesce(col(\"FLT_ATTENDANTS_PER_PASS\"), med_column))\n",
    "\n",
    "\n",
    "df = df.drop(\"AWND\").withColumnRenamed(\"AWND_filled\", \"AWND\")\n",
    "df = df.drop(\"PRCP\").withColumnRenamed(\"PRCP_filled\", \"PRCP\")\n",
    "df = df.drop(\"DISTANCE_GROUP\").withColumnRenamed(\"DISTANCE_GROUP_filled\", \"DISTANCE_GROUP\")\n",
    "df = df.drop(\"FLT_ATTENDANTS_PER_PASS\").withColumnRenamed(\"FLT_ATTENDANTS_PER_PASS_filled\", \"FLT_ATTENDANTS_PER_PASS\")\n",
    "\n",
    "nulls_and_empties_count = count_nulls_and_empties(df)\n",
    "\n",
    "# Show the result\n",
    "nulls_and_empties_count.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6a075780-d721-40c3-9517-ccffafbd1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2123:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+-----------------+\n",
      "|        CARRIER_NAME|Airport and City_match|monthly_avg_count|\n",
      "+--------------------+----------------------+-----------------+\n",
      "|American Airlines...|  Raleigh Durham In...|           3853.0|\n",
      "|   Endeavor Air Inc.|  Birmingham Intern...|            117.0|\n",
      "|Alaska Airlines Inc.|  John Wayne Airpor...|           1561.0|\n",
      "|Southwest Airline...|  Indianapolis Inte...|           4055.0|\n",
      "|Midwest Airline, ...|  Seattle Tacoma In...|             40.0|\n",
      "|American Airlines...|  Memphis Internati...|           1454.0|\n",
      "|Midwest Airline, ...|  General Mitchell ...|            252.0|\n",
      "|United Air Lines ...|  Orlando Executive...|           4663.0|\n",
      "|     JetBlue Airways|  North Island Nava...|            691.0|\n",
      "|United Air Lines ...|  Boise Air Termina...|            274.0|\n",
      "|   Endeavor Air Inc.|  Dane County Regio...|            315.0|\n",
      "|   Endeavor Air Inc.|  San Antonio De Lo...|            203.0|\n",
      "|United Air Lines ...|  Palm Beach County...|            927.0|\n",
      "|       Allegiant Air|  General Mitchell ...|             72.0|\n",
      "|American Airlines...|  Indianapolis Inte...|           1497.0|\n",
      "|United Air Lines ...|  Birmingham Intern...|             12.0|\n",
      "|Hawaiian Airlines...|  McCarran Internat...|            356.0|\n",
      "|United Air Lines ...|  Des Moines Intern...|            439.0|\n",
      "|SkyWest Airlines ...|  General Mitchell ...|           1896.0|\n",
      "|SkyWest Airlines ...|  McCarran Internat...|            724.0|\n",
      "+--------------------+----------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "calculate_flights = df.select(\"CARRIER_NAME\", \"Airport and City_match\", \"DATE_NEW\")\n",
    "\n",
    "calculate_flights = calculate_flights.withColumn(\"MONTH\", month(col(\"DATE_NEW\").alias(\"MONTH\")))\n",
    "\n",
    "count = calculate_flights.groupBy(\"CARRIER_NAME\", \"Airport and City_match\", \"MONTH\").count()\n",
    "#print(count.show())\n",
    "\n",
    "count = count.groupBy(\"CARRIER_NAME\", \"Airport and City_match\") \\\n",
    "                   .agg(round(avg(\"count\")).alias(\"monthly_avg_count\"))\n",
    "print(count.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "237a0403-0565-4b6b-b853-bd1a77a38289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2198:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+-----------+---------+------------+--------------+------------------+---------------+---------------------+-----------------------------+------------------------+--------------------+---------+--------------------+--------------------+----+----------+---------------+------------------+-----+-------------------+--------------+-----------------------+\n",
      "|        CARRIER_NAME|Airport and City_match|DAY_OF_WEEK|DEP_DEL15|DEP_TIME_BLK|SEGMENT_NUMBER|CONCURRENT_FLIGHTS|NUMBER_OF_SEATS|AIRPORT_FLIGHTS_MONTH|AIRLINE_AIRPORT_FLIGHTS_MONTH|AVG_MONTHLY_PASS_AIRPORT|GROUND_SERV_PER_PASS|PLANE_AGE|   DEPARTING_AIRPORT|    PREVIOUS_AIRPORT|SNOW|  DATE_NEW|EXTREME_WEATHER|EXTREME_WEATHER_WT| AWND|               PRCP|DISTANCE_GROUP|FLT_ATTENDANTS_PER_PASS|\n",
      "+--------------------+----------------------+-----------+---------+------------+--------------+------------------+---------------+---------------------+-----------------------------+------------------------+--------------------+---------+--------------------+--------------------+----+----------+---------------+------------------+-----+-------------------+--------------+-----------------------+\n",
      "|Delta Air Lines Inc.|  Boise Air Termina...|          1|        0|   0600-0659|             1|                10|            191|                 1727|                         93.0|                  171473|  0.0001486602009422|        1|  boise air terminal|                NONE| 0.0|2019-12-29|              0|                 2| 6.26|0.03999999910593033|           2.0|     0.0001441658849878|\n",
      "|SkyWest Airlines ...|  San Antonio De Lo...|          5|        0|   1800-1859|             4|                 7|             76|                 3359|                        352.0|                  401950|9.900278805864172...|        3|        san antonio |Salt Lake City In...| 0.0|2019-12-19|              1|                 0| 6.49|                0.0|           5.0|   3.419267401443636...|\n",
      "|Midwest Airline, ...|  Charleston Air Fo...|          1|        0|   0600-0659|             1|                 7|             76|                 2009|                        160.0|                  197188|  0.0001238227442279|        4|         charleston |                NONE| 0.0|2019-12-29|              1|                 1|  9.4| 0.6399999856948853|           3.0|   1.25293581928874e-06|\n",
      "|Delta Air Lines Inc.|  Tampa Internation...|          3|        1|   1900-1959|             5|                19|            199|                 7211|                       1050.0|                  874468|  0.0001486602009422|       18|              tampa |   Atlanta Municipal| 0.0|2019-12-17|              1|                 3|  8.5| 0.6800000071525574|           2.0|     0.0001441658849878|\n",
      "|American Airlines...|  Memphis Internati...|          2|        0|   0700-0759|             1|                 6|            128|                 2141|                        382.0|                  191927|   0.000177287219593|       19|            memphis |                NONE| 0.0|2019-12-23|              1|                 0| 6.93|                0.0|           3.0|   9.82082928995461e-05|\n",
      "|Southwest Airline...|  Orlando Executive...|          1|        1|   0900-0959|             2|                27|            143|                13019|                       3736.0|                 1823051|9.88941230999822e-05|       18|            orlando |Kansas City Inter...| 0.0|2019-12-01|              1|                 1|10.51|                0.0|           5.0|   6.178236301460919...|\n",
      "|American Eagle Ai...|  Miami Internation...|          3|        0|   2100-2159|             6|                34|             50|                 8367|                       1075.0|                 1413432|   0.000106867151749|       15|              miami |Port Columbus Int...| 0.0|2019-12-24|              1|                 0| 8.95|                0.0|           3.0|      0.000348407665605|\n",
      "|Atlantic Southeas...|  El Paso Internati...|          6|        0|   1400-1459|             2|                 4|             70|                 1517|                         42.0|                  145475|  0.0001998053656534|        0|            el paso |Houston Intercont...| 0.0|2019-12-13|              1|                 0| 9.17|                0.0|           3.0|                    0.0|\n",
      "|    Spirit Air Lines|  Seattle Tacoma In...|          5|        0|   1500-1559|             4|                35|            228|                12269|                        117.0|                 1960746|  0.0001246510730715|        1|            seattle |McCarran Internat...| 0.0|2019-12-26|              0|                 2| 6.04|0.05000000074505806|           4.0|   9.173723925704242...|\n",
      "|United Air Lines ...|  Austin Bergstrom ...|          2|        0|   1400-1459|             2|                12|            170|                 5567|                        625.0|                  690385|  0.0002289854734932|       26| austin - bergstrom |Newark Liberty In...| 0.0|2019-12-16|              1|                 2|15.66|                0.0|           7.0|     0.0002538042406215|\n",
      "|American Airlines...|  McCarran Internat...|          1|        0|   1000-1059|             2|                23|            187|                13152|                       1211.0|                 1903352|   0.000177287219593|       17|           mccarran |   Douglas Municipal| 0.0|2019-12-01|              1|                 0| 3.58|                0.0|           8.0|   9.82082928995461e-05|\n",
      "|     JetBlue Airways|  Palm Beach County...|          7|        0|   1900-1959|             3|                 6|            162|                 2716|                        806.0|                  283617|  0.0001268661761139|       16|         palm beach |Ronald Reagan Was...| 0.0|2019-12-28|              1|                 1|15.21| 2.2300000190734863|           5.0|     0.0001600389254787|\n",
      "|Midwest Airline, ...|  Newark Liberty In...|          4|        0|   2100-2159|             6|                20|             70|                11326|                       1902.0|                 1708599|  0.0001238227442279|       15|     newark liberty |   Douglas Municipal| 0.0|2019-12-11|              0|                 1|10.29| 0.1599999964237213|           5.0|   1.25293581928874e-06|\n",
      "|United Air Lines ...|  Newark Liberty In...|          3|        0|   1500-1559|             2|                26|            142|                11326|                       4895.0|                 1708599|  0.0002289854734932|       17|     newark liberty |Seattle Internati...| 0.0|2019-12-17|              0|                 3|10.96| 1.0299999713897705|           1.0|     0.0002538042406215|\n",
      "|  Mesa Airlines Inc.|  George Bush Inter...|          4|        0|   1000-1059|             2|                32|             66|                15165|                       3098.0|                 1690031|9.131157116170832...|       16|houston intercont...|Minneapolis-St Pa...| 0.0|2019-12-11|              1|                 0|10.07|                0.0|           4.0|                    0.0|\n",
      "|United Air Lines ...|  Washington Dulles...|          3|        1|   1700-1759|             2|                47|            291|                 5758|                       2375.0|                  780326|  0.0002289854734932|       19|  washington dulles |San Francisco Int...| 0.0|2019-12-31|              1|                 1| 7.61|                0.0|          10.0|     0.0002538042406215|\n",
      "|United Air Lines ...|  General Edward La...|          7|        1|   2000-2059|             3|                14|            173|                12223|                       1059.0|                 1472200|  0.0002289854734932|        5|              logan |Chicago O'Hare In...| 0.0|2019-12-28|              1|                 0|10.96|                0.0|           4.0|     0.0002538042406215|\n",
      "|Southwest Airline...|  St Louis Lambert ...|          5|        1|   1900-1959|             2|                20|            143|                 5594|                       3249.0|                  642980|9.88941230999822e-05|       20|  lambert-st. louis |Friendship Intern...| 0.0|2019-12-12|              1|                 0| 9.84|                0.0|           3.0|   6.178236301460919...|\n",
      "|Midwest Airline, ...|  Charleston Air Fo...|          1|        0|   0600-0659|             1|                 7|             76|                 2009|                        160.0|                  197188|  0.0001238227442279|        4|         charleston |                NONE| 0.0|2019-12-22|              1|                 1| 9.62| 0.6600000262260437|           3.0|   1.25293581928874e-06|\n",
      "|SkyWest Airlines ...|  San Francisco Int...|          2|        0|   0800-0859|             2|                42|             50|                13645|                       3304.0|                 1908862|9.900278805864172...|       17|      san francisco |  Boise Air Terminal| 0.0|2019-12-16|              1|                 0| 4.92|                0.0|           1.0|   3.419267401443636...|\n",
      "+--------------------+----------------------+-----------+---------+------------+--------------+------------------+---------------+---------------------+-----------------------------+------------------------+--------------------+---------+--------------------+--------------------+----+----------+---------------+------------------+-----+-------------------+--------------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rsdf = df.join(\n",
    "    count,\n",
    "    [\"CARRIER_NAME\", \"Airport and City_match\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "rsdf = rsdf.withColumn(\"AIRLINE_AIRPORT_FLIGHTS_MONTH\",\\\n",
    "                       when(\\\n",
    "                           (col(\"AIRLINE_AIRPORT_FLIGHTS_MONTH\").isNull() | (col(\"AIRLINE_AIRPORT_FLIGHTS_MONTH\") == ''))\n",
    "                           , col(\"monthly_avg_count\")).otherwise(col(\"AIRLINE_AIRPORT_FLIGHTS_MONTH\")))\n",
    "\n",
    "rsdf = rsdf.drop(\"monthly_avg_count\")\n",
    "\n",
    "rsdf.show()\n",
    "#nulls_and_empties_count = count_nulls_and_empties(rsdf)\n",
    "\n",
    "# Show the result\n",
    "#nulls_and_empties_count.show()\n",
    "\n",
    "\n",
    "result_df = result_joined\n",
    "#result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "cf93c537-7fbd-4dc7-85cf-9e0c887ec911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2247:=================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+-----------+---------+------------+--------------+------------------+---------------+---------------------+-----------------------------+------------------------+--------------------+---------+-----------------+----------------+----+--------+---------------+------------------+----+----+--------------+-----------------------+\n",
      "|CARRIER_NAME|Airport and City_match|DAY_OF_WEEK|DEP_DEL15|DEP_TIME_BLK|SEGMENT_NUMBER|CONCURRENT_FLIGHTS|NUMBER_OF_SEATS|AIRPORT_FLIGHTS_MONTH|AIRLINE_AIRPORT_FLIGHTS_MONTH|AVG_MONTHLY_PASS_AIRPORT|GROUND_SERV_PER_PASS|PLANE_AGE|DEPARTING_AIRPORT|PREVIOUS_AIRPORT|SNOW|DATE_NEW|EXTREME_WEATHER|EXTREME_WEATHER_WT|AWND|PRCP|DISTANCE_GROUP|FLT_ATTENDANTS_PER_PASS|\n",
      "+------------+----------------------+-----------+---------+------------+--------------+------------------+---------------+---------------------+-----------------------------+------------------------+--------------------+---------+-----------------+----------------+----+--------+---------------+------------------+----+----+--------------+-----------------------+\n",
      "|           0|                     0|          0|        0|           0|             0|                 0|              0|                    0|                            0|                       0|                   0|        0|                0|               0|   0|       0|              0|                 0|   0|   0|             0|                      0|\n",
      "+------------+----------------------+-----------+---------+------------+--------------+------------------+---------------+---------------------+-----------------------------+------------------------+--------------------+---------+-----------------+----------------+----+--------+---------------+------------------+----+----+--------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = rsdf\n",
    "\n",
    "nulls_and_empties_count = count_nulls_and_empties(df)\n",
    "\n",
    "# Show the result\n",
    "nulls_and_empties_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "366e1396-fa90-47ce-a4f5-88af0c4c30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 19:57:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , MONTH, DAY_OF_WEEK, DEP_DEL15, DEP_TIME_BLK, DISTANCE_GROUP, SEGMENT_NUMBER, CONCURRENT_FLIGHTS, NUMBER_OF_SEATS, CARRIER_NAME, AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH, AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE, FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS, PLANE_AGE, DEPARTING_AIRPORT, LATITUDE, LONGITUDE, PREVIOUS_AIRPORT\n",
      " Schema: _c0, MONTH, DAY_OF_WEEK, DEP_DEL15, DEP_TIME_BLK, DISTANCE_GROUP, SEGMENT_NUMBER, CONCURRENT_FLIGHTS, NUMBER_OF_SEATS, CARRIER_NAME, AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH, AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE, FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS, PLANE_AGE, DEPARTING_AIRPORT, LATITUDE, LONGITUDE, PREVIOUS_AIRPORT\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/mate/repos/LuckaEvolucne/full_data_flightdelay.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|DEP_DEL15|  count|\n",
      "+---------+-------+\n",
      "|        0|1227342|\n",
      "|        1| 277948|\n",
      "+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/03 19:58:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , MONTH, DAY_OF_WEEK, DEP_DEL15, DEP_TIME_BLK, DISTANCE_GROUP, SEGMENT_NUMBER, CONCURRENT_FLIGHTS, NUMBER_OF_SEATS, CARRIER_NAME, AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH, AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE, FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS, PLANE_AGE, DEPARTING_AIRPORT, LATITUDE, LONGITUDE, PREVIOUS_AIRPORT\n",
      " Schema: _c0, MONTH, DAY_OF_WEEK, DEP_DEL15, DEP_TIME_BLK, DISTANCE_GROUP, SEGMENT_NUMBER, CONCURRENT_FLIGHTS, NUMBER_OF_SEATS, CARRIER_NAME, AIRPORT_FLIGHTS_MONTH, AIRLINE_FLIGHTS_MONTH, AIRLINE_AIRPORT_FLIGHTS_MONTH, AVG_MONTHLY_PASS_AIRPORT, AVG_MONTHLY_PASS_AIRLINE, FLT_ATTENDANTS_PER_PASS, GROUND_SERV_PER_PASS, PLANE_AGE, DEPARTING_AIRPORT, LATITUDE, LONGITUDE, PREVIOUS_AIRPORT\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/mate/repos/LuckaEvolucne/full_data_flightdelay.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 903109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 896:==================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dataset Count: 602357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing batches\n",
    "fractions = {label: 0.1 for label in result_df.select(\"DEP_DEL15\").distinct().rdd.flatMap(lambda x: x).collect()}\n",
    "sampled_df = result_df.stat.sampleBy(\"DEP_DEL15\", fractions, seed=1234)\n",
    "\n",
    "# Show the sampled data distribution\n",
    "sampled_df.groupBy(\"DEP_DEL15\").count().show()\n",
    "\n",
    "# Split the DataFrame into training (60%) and test (40%) sets\n",
    "train_df, test_df = sampled_df.randomSplit([0.6, 0.4], seed=1234)\n",
    "\n",
    "# Show the size of each set\n",
    "print(\"Training Dataset Count: \" + str(train_df.count()))\n",
    "print(\"Testing Dataset Count: \" + str(test_df.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae857cd-5074-426f-9b12-da9a6f0e4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert precipitation from numerical to nominal\n",
    "\n",
    "# Calculate the quantile thresholds\n",
    "thresholds = result_df.approxQuantile(\"PRCP\", [0.33, 0.67], 0.01)  # 0.01 is the relative error\n",
    "\n",
    "# Categorize based on quantile thresholds\n",
    "result_df = result_df.withColumn(\n",
    "    \"precip_category\",\n",
    "    when(col(\"PRCP\") <= thresholds[0], \"low\")\n",
    "    .when(col(\"PRCP\") <= thresholds[1], \"medium\")\n",
    "    .otherwise(\"high\")\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "result_df.select(\"PRCP\", \"precip_category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278da19-b80b-4dd8-84d9-f988a68b65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform month from numerical to nominal\n",
    "\n",
    "\n",
    "# Month mapping dictionary\n",
    "month_dict = {\n",
    "    '1': 'January', '2': 'February', '3': 'March', '4': 'April', \n",
    "    '5': 'May', '6': 'June', '7': 'July', '8': 'August', \n",
    "    '9': 'September', '10': 'October', '11': 'November', '12': 'December'\n",
    "}\n",
    "\n",
    "# Define the UDF to convert numerical months to names\n",
    "def convert_month_to_name(month):\n",
    "    return month_dict.get(str(month), \"Unknown\")\n",
    "\n",
    "convert_month_udf = udf(convert_month_to_name, StringType())\n",
    "\n",
    "# Apply the UDF to create a new column with month names\n",
    "df_with_months = result_df.withColumn(\"MONTH_NAME\", convert_month_udf(result_df[\"MONTH\"]))\n",
    "result_df = df_with_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676654e-66b7-41ae-a093-f10e7832b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform weekday from numerical to nominal\n",
    "\n",
    "# Weekday mapping dictionary\n",
    "month_dict = {\n",
    "    '1': 'Monday', '2': 'Tuesday', '3': 'Wednesday', '4': 'Thursday', \n",
    "    '5': 'Friday', '6': 'Saturday', '7': 'Sunday'}\n",
    "\n",
    "# Define the UDF to convert numerical months to names\n",
    "def convert_weekday_to_name(weekday):\n",
    "    return month_dict.get(str(weekday), \"Unknown\")\n",
    "\n",
    "convert_weekday_udf = udf(convert_weekday_to_name, StringType())\n",
    "\n",
    "# Apply the UDF to create a new column with month names\n",
    "df_with_months = result_df.withColumn(\"DAY_OF_WEEK_NAME\", convert_weekday_udf(result_df[\"DAY_OF_WEEK\"]))\n",
    "#df_with_months.show(n=1)\n",
    "df_with_months = df_with_months.drop(\"DAY_OF_WEEK\").withColumnRenamed(\"DAY_OF_WEEK_NAME\", \"DAY_OF_WEEK\")\n",
    "\n",
    "result_df = df_with_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "85d45649-18f7-41b7-bd6e-2ecee5b3df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMBER_OF_SEATS into nominal\n",
    "\n",
    "# Categorize based on research\n",
    "result_df = result_df.withColumn(\n",
    "    \"NUMBER_OF_SEATS_NOM\",\n",
    "    when(col(\"NUMBER_OF_SEATS\") <= 100, \"Small\")\n",
    "    .when(col(\"NUMBER_OF_SEATS\") <= 200, \"Medium\")\n",
    "    .when(col(\"NUMBER_OF_SEATS\") <= 400, \"Large\")\n",
    "    .otherwise(\"Jumbo\")\n",
    ")\n",
    "\n",
    "# Replace NUMBER_OF_SEATS column with the nominal one\n",
    "result_df = result_df.drop(\"NUMBER_OF_SEATS\").withColumnRenamed(\"NUMBER_OF_SEATS_NOM\", \"NUMBER_OF_SEATS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c8aee-bbab-4d38-a8d9-37cb1293e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plane age into nominal\n",
    "\n",
    "# Categorize based on research\n",
    "result_df = result_df.withColumn(\n",
    "    \"PLANE_AGE_NOM\",\n",
    "    when(col(\"PLANE_AGE\") <= 10, \"New\")\n",
    "    .when(col(\"PLANE_AGE\") <= 20, \"Standard\")\n",
    "    .otherwise(\"Old\")\n",
    ")\n",
    "\n",
    "# Replace PLANE_AGE column with the nominal one\n",
    "result_df = result_df.drop(\"PLANE_AGE\").withColumnRenamed(\"PLANE_AGE_NOM\", \"PLANE_AGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8953a3-a05f-40c2-bbab-7bba3b16ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
